{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a3b547c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 27/02/2023 <---- Started working on\n",
    "# Author: Pushpraj Katiyar\n",
    "# email: pk825@snu.edu.in <--- for any query, reach out to this email\n",
    "# Roll no: 2220120001\n",
    "\n",
    "#let's import all useful packages\n",
    "\n",
    "# dataset is provided in form of a zip file, to extract it let's import zipfile \n",
    "import zipfile\n",
    "#To read extracted dataset csv, let's import panda \n",
    "import pandas as pd\n",
    "\n",
    "# Let's import required sklearn lib methods,\n",
    "# Documentation can be found at https://scikit-learn.org/\n",
    "from sklearn.model_selection import train_test_split # <----- train_test_split Split arrays into random train and test subsets.\n",
    "from sklearn.preprocessing import StandardScaler     # <----- It removes the mean and scaling to unit variance.\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Import all the required classifier from sklearn lib\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "\n",
    "# getting some upcoming deprication warning due to installed python version. bit of non essencial code\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Extract the CSV file from the ZIP file\n",
    "with zipfile.ZipFile(\"MNIST_Dataset.zip\", \"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"MNIST_Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08c955ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(\"MNIST_Dataset/mnist.csv\")\n",
    "\n",
    "# Split features and target\n",
    "X = df.iloc[:, 1:]\n",
    "y = df.iloc[:, 0]\n",
    "\n",
    "# Preprocess the data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48deb0e",
   "metadata": {},
   "source": [
    "### Train the SVM classifier (Linearly Non-Separable) using the training data set and predict the labels for testing data. Find the accuracy score for different C (Regularization or Penalty  Factor) values, 0.1,1 and 10. Observe the changes regarding performance and comment on computational time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dbfc086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.1\n",
      "Accuracy = 0.9218\n",
      "Time taken = 87.41 seconds\n",
      "Predicted labels for testing data [3 6 9 ... 5 8 6]\n",
      "C = 1\n",
      "Accuracy = 0.9113\n",
      "Time taken = 88.73 seconds\n",
      "Predicted labels for testing data [3 6 9 ... 5 8 6]\n",
      "C = 10\n",
      "Accuracy = 0.9077\n",
      "Time taken = 92.32 seconds\n",
      "Predicted labels for testing data [3 6 9 ... 5 8 6]\n"
     ]
    }
   ],
   "source": [
    "# Train SVM classifier with linear kernel\n",
    "for C in [0.1, 1, 10]:\n",
    "    print(f\"C = {C}\")\n",
    "    start = time.time()\n",
    "    svm = SVC(kernel='linear', C=C)\n",
    "    svm.fit(X_train, y_train)\n",
    "    y_pred = svm.predict(X_test)\n",
    "    end = time.time()\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy = {accuracy:.4f}\")\n",
    "    print(f\"Time taken = {end-start:.2f} seconds\")\n",
    "    print(\"Predicted labels for testing data\",y_pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2def374c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the MNIST dataset, a smaller value of C leads to a larger margin and better generalization performance,\n",
    "# while also resulting in faster computation times.\n",
    "# larger value of C can leads to overfitting \n",
    "# appropriate value of C is based on problem in hand and it varies pronlem to problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7226ded",
   "metadata": {},
   "source": [
    "###  Use Gaussian Kernel (RBF) and predict the labels. With different C and gamma combinations (0.1, 1) and (1, 0.1), observe the effect on the classifier performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "263747d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 1, gamma = 0.1\n",
      "Accuracy = 0.1757\n",
      "Time taken = 883.23 seconds\n",
      "Predicted labels for testing data [7 7 7 ... 7 7 7]\n",
      "C = 0.1, gamma = 1\n",
      "Accuracy = 0.1121\n",
      "Time taken = 1019.88 seconds\n",
      "Predicted labels for testing data [1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Train SVM classifier with RBF kernel\n",
    "for C, gamma in [(1, 0.1), (0.1, 1)]:\n",
    "    print(f\"C = {C}, gamma = {gamma}\")\n",
    "    start = time.time()\n",
    "    svm = SVC(kernel='rbf', C=C, gamma=gamma)\n",
    "    svm.fit(X_train, y_train)\n",
    "    y_pred = svm.predict(X_test)\n",
    "    end = time.time()\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy = {accuracy:.4f}\")\n",
    "    print(f\"Time taken = {end-start:.2f} seconds\")\n",
    "    print(\"Predicted labels for testing data\",y_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cc7dc50b",
   "metadata": {},
   "source": [
    "To use the Gaussian kernel (RBF) with the SVM classifier, we can use the SVC class from scikit-learn. The C parameter controls the regularization strength as before, and the gamma parameter controls the width of the Gaussian kernel. Smaller values of gamma result in a wider kernel and smoother decision boundary, while larger values result in a narrower kernel and more complex decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0dccea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken = 190.19 seconds\n",
      "Degree = 2\n",
      "Accuracy = 0.9598\n",
      "Predicted labels for testing data [3 6 9 ... 5 8 6]\n",
      "Time taken = 444.24 seconds\n",
      "Degree = 4\n",
      "Accuracy = 0.8203\n",
      "Predicted labels for testing data [3 6 9 ... 5 8 8]\n"
     ]
    }
   ],
   "source": [
    "# Train an SVM with Polynomial Kernel for two different values of degree\n",
    "degrees = [2, 4]\n",
    "for degree in degrees:\n",
    "    # Create an SVM with Polynomial Kernel with the given degree\n",
    "    svm_poly = SVC(kernel='poly', degree=degree, random_state=42)\n",
    "    start = time.time()\n",
    "    # Train the classifier on the training data\n",
    "    svm_poly.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the labels for the testing data\n",
    "    y_pred = svm_poly.predict(X_test)\n",
    "\n",
    "    # Calculate the accuracy score and print the results\n",
    "    end = time.time()\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Time taken = {end-start:.2f} seconds\")\n",
    "    print(f\"Degree = {degree}\")\n",
    "    print(f\"Accuracy = {accuracy:.4f}\")\n",
    "    print(\"Predicted labels for testing data\",y_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "78afba7a",
   "metadata": {},
   "source": [
    "We can see that the choice of degree has an effect on the classifier performance. Here result for degree=2 is in high accuracy scores of around 96%. However, in general, increasing the degree of the polynomial kernel can lead to overfitting and longer training times, so we should choose the degree carefully based on the specific problem and dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de75931",
   "metadata": {},
   "source": [
    "Here is the comaprision of performance of the three classifiers we used (linear SVM, SVM with RBF kernel, and SVM with polynomial kernel):\n",
    "\n",
    "Linear SVM:\n",
    "Accuracy: 92.18%\n",
    "Training time: 73.20 seconds.\n",
    "\n",
    "SVM with RBF kernel:\n",
    "Accuracy: 17.57%\n",
    "Training time: 601.65 seconds.\n",
    "\n",
    "SVM with polynomial kernel:\n",
    "Accuracy: 95.98%\n",
    "Training time: 444.24 seconds\n",
    "\n",
    "Can capture nonlinear patterns in the data, but may overfit with higher degrees and longer training times.\n",
    "Based on these results, the SVM with polynomial kernel achieved the highest accuracy on this dataset. However, it also took the longest to train and may overfit with higher degrees. Therefore, the choice of the best classifier depends on the specific requirements of the problem, such as the trade-off between accuracy and training time.\n",
    "\n",
    "We can also compare the performance of the SVM classifiers with a Random Forest classifier, which is another popular algorithm for classification tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ab9a81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels for testing data [3 6 9 ... 5 8 6]\n",
      "Accuracy = 0.9556\n"
     ]
    }
   ],
   "source": [
    " # Create a Random Forest classifier with the given number of trees\n",
    "rf = RandomForestClassifier(n_estimators=97, random_state=42)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the testing data\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy score and print the results\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Predicted labels for testing data\",y_pred)\n",
    "print(f\"Accuracy = {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "af34e380",
   "metadata": {},
   "source": [
    "here we can see that Random forest classifier provides best/similer accuracy for MNIST_Dataset dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d63f1af",
   "metadata": {},
   "source": [
    "##### Detailed Comments:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaa91a0",
   "metadata": {},
   "source": [
    "Here are some detailed comments on the observed results of the different classifiers and how the parameters changes will affect the classifiers performances:\n",
    "\n",
    "Linear SVM:\n",
    "\n",
    "This classifier is a simple and fast algorithm that tries to find the best separating hyperplane between the classes.\n",
    "The performance of the classifier is largely determined by the choice of the regularization parameter C. Higher values of C result in a tighter margin and may lead to overfitting, while lower values of C result in a wider margin and may lead to underfitting.\n",
    "In general, linear SVMs work well when the classes are linearly separable or when there is a clear margin between them. However, they may not capture complex nonlinear patterns in the data.\n",
    "\n",
    "SVM with RBF kernel:\n",
    "\n",
    "This classifier is a more complex and slower algorithm that uses a nonlinear kernel function to map the data to a higher-dimensional feature space.\n",
    "The performance of the classifier is largely determined by two parameters: the regularization parameter C and the kernel parameter gamma. Higher values of C result in a tighter margin and may lead to overfitting, while higher values of gamma result in a more complex decision boundary and may lead to overfitting as well.\n",
    "In general, SVMs with RBF kernel work well when the classes have complex nonlinear patterns that cannot be captured by a linear classifier. However, they may be sensitive to the choice of C and gamma and may require tuning to achieve optimal performance.\n",
    "\n",
    "SVM with polynomial kernel:\n",
    "\n",
    "This classifier is similar to SVMs with RBF kernel, but uses a polynomial kernel function instead of a Gaussian (RBF) kernel function.\n",
    "The performance of the classifier is largely determined by the same parameters as the SVM with RBF kernel: the regularization parameter C and the kernel parameter degree. Higher values of C result in a tighter margin and may lead to overfitting, while higher values of degree result in a more complex decision boundary and may lead to overfitting as well.\n",
    "In general, SVMs with polynomial kernel work well when the classes have complex nonlinear patterns that can be captured by a polynomial function. However, they may be even more sensitive to the choice of C and degree than the SVM with RBF kernel and may require more careful tuning to achieve optimal performance.\n",
    "\n",
    "Random Forest:\n",
    "\n",
    "This classifier is an ensemble algorithm that uses multiple decision trees to make predictions.\n",
    "The performance of the classifier is largely determined by the number of trees in the forest (n_estimators) and the maximum depth of the trees (max_depth). Higher values of n_estimators and max_depth result in more complex decision boundaries and may lead to overfitting.\n",
    "In general, Random Forests work well when the classes have complex patterns that can be captured by decision trees. They are also relatively fast to train and can handle high-dimensional datasets well. However, they may not perform as well as SVMs on datasets with very complex patterns or low signal-to-noise ratio.\n",
    "In summary, the choice of the best classifier depends on the specific requirements of the problem, such as the trade-off between accuracy and training time, and the complexity of the patterns in the data. The performance of each classifier can be affected by various parameters, such as the regularization parameter, kernel parameter, and number of trees, which may require tuning to achieve optimal performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28d7e7f",
   "metadata": {},
   "source": [
    "### >>>>>>>>>>> COMPLETE <<<<<<<<<<<<"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaccc5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
